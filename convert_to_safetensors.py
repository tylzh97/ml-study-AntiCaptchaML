#!/usr/bin/env python3
"""
PyTorchæ¨¡å‹è½¬SafeTensorsæ ¼å¼å·¥å…·
"""
import os
import argparse
import torch
import json
from pathlib import Path


def convert_pytorch_to_safetensors(pytorch_path, output_dir=None):
    """
    å°†PyTorchæ ¼å¼æ¨¡å‹è½¬æ¢ä¸ºSafeTensorsæ ¼å¼
    
    Args:
        pytorch_path: PyTorchæ¨¡å‹è·¯å¾„ (.pthæ–‡ä»¶)
        output_dir: è¾“å‡ºç›®å½•ï¼Œé»˜è®¤ä¸è¾“å…¥æ–‡ä»¶åŒç›®å½•
    """
    try:
        from safetensors.torch import save_file
    except ImportError:
        print("âŒ safetensorsåº“æœªå®‰è£…ï¼Œè¯·å®‰è£…: pip install safetensors")
        return False
    
    pytorch_path = Path(pytorch_path)
    if not pytorch_path.exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {pytorch_path}")
        return False
    
    # è®¾ç½®è¾“å‡ºè·¯å¾„
    if output_dir is None:
        output_dir = pytorch_path.parent
    else:
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
    
    base_name = pytorch_path.stem
    
    # è¾“å‡ºæ–‡ä»¶è·¯å¾„
    safetensor_path = output_dir / f"{base_name}.safetensors"
    metadata_path = output_dir / f"{base_name}_metadata.json"
    optimizer_path = output_dir / f"{base_name}_optimizer.pth"
    
    print(f"ğŸ“¥ åŠ è½½PyTorchæ¨¡å‹: {pytorch_path}")
    
    try:
        # åŠ è½½PyTorchæ£€æŸ¥ç‚¹
        checkpoint = torch.load(pytorch_path, map_location='cpu')
        
        if 'model_state_dict' not in checkpoint:
            print("âŒ æ£€æŸ¥ç‚¹æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼Œç¼ºå°‘ model_state_dict")
            return False
        
        # 1. ä¿å­˜æ¨¡å‹æƒé‡ä¸ºsafetensors
        print(f"ğŸ’¾ ä¿å­˜æ¨¡å‹æƒé‡: {safetensor_path}")
        save_file(checkpoint['model_state_dict'], str(safetensor_path))
        
        # 2. ä¿å­˜å…ƒæ•°æ®ä¸ºJSON
        metadata = {
            'epoch': checkpoint.get('epoch', 0),
            'val_loss': checkpoint.get('val_loss', 0.0),
            'val_acc': checkpoint.get('val_acc', 0.0),
            'train_losses': checkpoint.get('train_losses', []),
            'val_losses': checkpoint.get('val_losses', []),
            'val_accuracies': checkpoint.get('val_accuracies', [])
        }
        
        print(f"ğŸ“‹ ä¿å­˜è®­ç»ƒå…ƒæ•°æ®: {metadata_path}")
        with open(metadata_path, 'w') as f:
            json.dump(metadata, f, indent=2)
        
        # 3. ä¿å­˜ä¼˜åŒ–å™¨çŠ¶æ€ä¸ºPyTorchæ ¼å¼
        optimizer_data = {}
        if 'optimizer_state_dict' in checkpoint:
            optimizer_data['optimizer_state_dict'] = checkpoint['optimizer_state_dict']
        if 'scheduler_state_dict' in checkpoint:
            optimizer_data['scheduler_state_dict'] = checkpoint['scheduler_state_dict']
        
        if optimizer_data:
            print(f"âš™ï¸ ä¿å­˜ä¼˜åŒ–å™¨çŠ¶æ€: {optimizer_path}")
            torch.save(optimizer_data, optimizer_path)
        
        # éªŒè¯æ–‡ä»¶å¤§å°
        original_size = pytorch_path.stat().st_size
        safetensor_size = safetensor_path.stat().st_size
        
        print(f"\nâœ… è½¬æ¢å®Œæˆ!")
        print(f"ğŸ“Š æ–‡ä»¶å¤§å°å¯¹æ¯”:")
        print(f"  åŸå§‹æ–‡ä»¶: {original_size:,} bytes ({original_size/1024/1024:.1f} MB)")
        print(f"  SafeTensor: {safetensor_size:,} bytes ({safetensor_size/1024/1024:.1f} MB)")
        print(f"  å‹ç¼©æ¯”: {safetensor_size/original_size:.2%}")
        
        print(f"\nğŸ“ è¾“å‡ºæ–‡ä»¶:")
        print(f"  æ¨¡å‹æƒé‡: {safetensor_path}")
        print(f"  è®­ç»ƒå…ƒæ•°æ®: {metadata_path}")
        if optimizer_data:
            print(f"  ä¼˜åŒ–å™¨çŠ¶æ€: {optimizer_path}")
        
        return True
        
    except Exception as e:
        print(f"âŒ è½¬æ¢å¤±è´¥: {e}")
        return False


def batch_convert(input_dir, output_dir=None):
    """æ‰¹é‡è½¬æ¢ç›®å½•ä¸­çš„æ‰€æœ‰.pthæ–‡ä»¶"""
    input_dir = Path(input_dir)
    if not input_dir.exists():
        print(f"âŒ è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {input_dir}")
        return
    
    pth_files = list(input_dir.glob("*.pth"))
    if not pth_files:
        print(f"âŒ åœ¨ {input_dir} ä¸­æœªæ‰¾åˆ°.pthæ–‡ä»¶")
        return
    
    print(f"ğŸ” å‘ç° {len(pth_files)} ä¸ªPyTorchæ¨¡å‹æ–‡ä»¶")
    
    success_count = 0
    for pth_file in pth_files:
        print(f"\n{'='*50}")
        if convert_pytorch_to_safetensors(pth_file, output_dir):
            success_count += 1
    
    print(f"\nğŸ‰ æ‰¹é‡è½¬æ¢å®Œæˆ: {success_count}/{len(pth_files)} æˆåŠŸ")


def main():
    parser = argparse.ArgumentParser(description='PyTorchæ¨¡å‹è½¬SafeTensorsæ ¼å¼å·¥å…·')
    parser.add_argument('input_path', type=str, 
                        help='è¾“å…¥æ–‡ä»¶è·¯å¾„(.pth)æˆ–ç›®å½•')
    parser.add_argument('--output_dir', type=str, 
                        help='è¾“å‡ºç›®å½•ï¼Œé»˜è®¤ä¸è¾“å…¥æ–‡ä»¶åŒç›®å½•')
    parser.add_argument('--batch', action='store_true',
                        help='æ‰¹é‡è½¬æ¢æ¨¡å¼ï¼ˆè¾“å…¥è·¯å¾„ä¸ºç›®å½•ï¼‰')
    
    args = parser.parse_args()
    
    print("ğŸ”„ PyTorch â†’ SafeTensors è½¬æ¢å·¥å…·")
    print("=" * 50)
    
    if args.batch:
        batch_convert(args.input_path, args.output_dir)
    else:
        convert_pytorch_to_safetensors(args.input_path, args.output_dir)


if __name__ == "__main__":
    main()