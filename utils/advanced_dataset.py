import os
import torch
from torch.utils.data import DataLoader
from .dataset import CaptchaDataset, collate_fn
from .advanced_transforms import AdvancedCaptchaDataset, create_advanced_transforms


def create_advanced_data_loaders(data_root, batch_size=32, num_workers=4, 
                                img_height=60, img_width=160, 
                                augment_strength='medium'):
    """
    åˆ›å»ºå¸¦é«˜çº§æ•°æ®å¢å¼ºçš„æ•°æ®åŠ è½½å™¨
    
    Args:
        data_root: æ•°æ®æ ¹ç›®å½•
        batch_size: æ‰¹æ¬¡å¤§å°
        num_workers: æ•°æ®åŠ è½½çº¿ç¨‹æ•°
        img_height: å›¾åƒé«˜åº¦
        img_width: å›¾åƒå®½åº¦
        augment_strength: å¢å¼ºå¼ºåº¦ ('light', 'medium', 'heavy')
    
    Returns:
        train_loader, val_loader, test_loader, train_dataset
    """
    
    # åˆ›å»ºå˜æ¢
    train_transform = create_advanced_transforms(
        img_height, img_width, is_train=True, augment_strength=augment_strength
    )
    val_transform = create_advanced_transforms(
        img_height, img_width, is_train=False
    )
    
    # åˆ›å»ºæ•°æ®é›†
    train_dataset = AdvancedCaptchaDataset(
        os.path.join(data_root, 'train'),
        augment_strength=augment_strength,
        transform=train_transform
    )
    
    val_dataset = AdvancedCaptchaDataset(
        os.path.join(data_root, 'val'),
        augment_strength='light',  # éªŒè¯é›†ç”¨è½»åº¦å¢å¼º
        transform=val_transform
    )
    
    test_dataset = AdvancedCaptchaDataset(
        os.path.join(data_root, 'test'),
        augment_strength=None,  # æµ‹è¯•é›†ä¸å¢å¼º
        transform=val_transform
    )
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=num_workers,
        collate_fn=collate_fn,
        pin_memory=True
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        collate_fn=collate_fn,
        pin_memory=True
    )
    
    test_loader = DataLoader(
        test_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        collate_fn=collate_fn,
        pin_memory=True
    )
    
    return train_loader, val_loader, test_loader, train_dataset


def preview_augmentations(data_root, num_samples=8, augment_strength='medium'):
    """
    é¢„è§ˆæ•°æ®å¢å¼ºæ•ˆæœ
    
    Args:
        data_root: æ•°æ®æ ¹ç›®å½•
        num_samples: é¢„è§ˆæ ·æœ¬æ•°
        augment_strength: å¢å¼ºå¼ºåº¦
    """
    import matplotlib.pyplot as plt
    from .dataset import CaptchaDataset
    
    # åˆ›å»ºåŸå§‹æ•°æ®é›†å’Œå¢å¼ºæ•°æ®é›†
    original_dataset = CaptchaDataset(
        os.path.join(data_root, 'train'),
        transform=create_advanced_transforms(60, 160, is_train=False)
    )
    
    augmented_dataset = AdvancedCaptchaDataset(
        os.path.join(data_root, 'train'),
        augment_strength=augment_strength
    )
    
    fig, axes = plt.subplots(2, num_samples, figsize=(16, 6))
    fig.suptitle(f'æ•°æ®å¢å¼ºé¢„è§ˆ (å¼ºåº¦: {augment_strength})', fontsize=14)
    
    for i in range(num_samples):
        # åŸå§‹å›¾åƒ
        orig_img, _, _, orig_text = original_dataset[i]
        orig_img = orig_img.permute(1, 2, 0)  # CHW -> HWC
        # åå½’ä¸€åŒ–
        mean = [0.485, 0.456, 0.406]
        std = [0.229, 0.224, 0.225]
        for c in range(3):
            orig_img[:, :, c] = orig_img[:, :, c] * std[c] + mean[c]
        orig_img = torch.clamp(orig_img, 0, 1)
        
        # å¢å¼ºå›¾åƒ
        aug_img, _, _, aug_text = augmented_dataset[i]
        aug_img = aug_img.permute(1, 2, 0)
        for c in range(3):
            aug_img[:, :, c] = aug_img[:, :, c] * std[c] + mean[c]
        aug_img = torch.clamp(aug_img, 0, 1)
        
        # æ˜¾ç¤º
        axes[0, i].imshow(orig_img)
        axes[0, i].set_title(f'åŸå§‹: {orig_text}')
        axes[0, i].axis('off')
        
        axes[1, i].imshow(aug_img)
        axes[1, i].set_title(f'å¢å¼º: {aug_text}')
        axes[1, i].axis('off')
    
    plt.tight_layout()
    plt.show()


if __name__ == "__main__":
    import torch
    
    # æµ‹è¯•é«˜çº§æ•°æ®åŠ è½½å™¨
    data_root = "./data"
    
    if os.path.exists(data_root):
        print("ğŸ§ª æµ‹è¯•é«˜çº§æ•°æ®å¢å¼ºåŠ è½½å™¨...")
        
        # åˆ›å»ºä¸åŒå¼ºåº¦çš„æ•°æ®åŠ è½½å™¨
        for strength in ['light', 'medium', 'heavy']:
            print(f"\nğŸ“Š æµ‹è¯•å¢å¼ºå¼ºåº¦: {strength}")
            
            train_loader, val_loader, test_loader, train_dataset = create_advanced_data_loaders(
                data_root, batch_size=4, augment_strength=strength
            )
            
            # æµ‹è¯•ä¸€ä¸ªæ‰¹æ¬¡
            for batch_idx, (images, text_indices, text_lengths, texts) in enumerate(train_loader):
                print(f"  æ‰¹æ¬¡ {batch_idx}:")
                print(f"    å›¾åƒå½¢çŠ¶: {images.shape}")
                print(f"    æ–‡æœ¬: {texts}")
                break
        
        print("\nâœ… é«˜çº§æ•°æ®åŠ è½½å™¨æµ‹è¯•å®Œæˆ!")
        
        # å¦‚æœæœ‰matplotlibï¼Œæ˜¾ç¤ºé¢„è§ˆ
        try:
            preview_augmentations(data_root, num_samples=4, augment_strength='medium')
        except ImportError:
            print("âš ï¸ matplotlibæœªå®‰è£…ï¼Œè·³è¿‡å¯è§†åŒ–é¢„è§ˆ")
    
    else:
        print(f"âŒ æ•°æ®ç›®å½• {data_root} ä¸å­˜åœ¨")