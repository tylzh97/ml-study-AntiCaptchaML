#!/usr/bin/env python3
"""
è®­ç»ƒé—®é¢˜è¯Šæ–­è„šæœ¬
"""
import os
import torch
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt

from models import CRNN, BasicCRNN, ResNetCRNN
from utils import create_data_loaders, CaptchaDataset


def check_data_quality(data_root):
    """æ£€æŸ¥æ•°æ®è´¨é‡"""
    print("ğŸ” æ•°æ®è´¨é‡æ£€æŸ¥")
    print("=" * 50)
    
    # æ£€æŸ¥ç›®å½•ç»“æ„
    for split in ['train', 'val', 'test']:
        split_dir = os.path.join(data_root, split)
        if os.path.exists(split_dir):
            labels_file = os.path.join(split_dir, 'labels.txt')
            if os.path.exists(labels_file):
                with open(labels_file, 'r') as f:
                    lines = f.readlines()
                print(f"âœ… {split}: {len(lines)} æ ·æœ¬")
                
                # æ£€æŸ¥å‰å‡ ä¸ªæ ·æœ¬
                print(f"   å‰3ä¸ªæ ·æœ¬:")
                for i, line in enumerate(lines[:3]):
                    parts = line.strip().split('\t')
                    if len(parts) == 2:
                        img_name, text = parts
                        img_path = os.path.join(split_dir, img_name)
                        exists = "âœ…" if os.path.exists(img_path) else "âŒ"
                        print(f"   {exists} {img_name} -> '{text}' (é•¿åº¦:{len(text)})")
                    else:
                        print(f"   âŒ æ ¼å¼é”™è¯¯: {line.strip()}")
            else:
                print(f"âŒ {split}: labels.txt ä¸å­˜åœ¨")
        else:
            print(f"âŒ {split}: ç›®å½•ä¸å­˜åœ¨")


def test_dataloader(data_root):
    """æµ‹è¯•æ•°æ®åŠ è½½å™¨"""
    print("\nğŸ“Š æ•°æ®åŠ è½½å™¨æµ‹è¯•")
    print("=" * 50)
    
    try:
        train_loader, val_loader, test_loader, dataset = create_data_loaders(
            data_root, batch_size=4, num_workers=0
        )
        
        print(f"âœ… æ•°æ®é›†åˆ›å»ºæˆåŠŸ")
        print(f"   å­—ç¬¦é›†å¤§å°: {dataset.num_classes}")
        print(f"   å­—ç¬¦é›†: {dataset.characters}")
        
        # æµ‹è¯•è®­ç»ƒæ•°æ®
        print(f"\nğŸ“ˆ è®­ç»ƒæ•°æ®æµ‹è¯•:")
        for i, (images, text_indices, text_lengths, texts) in enumerate(train_loader):
            print(f"   æ‰¹æ¬¡ {i+1}:")
            print(f"     å›¾åƒå½¢çŠ¶: {images.shape}")
            print(f"     æ–‡æœ¬: {texts}")
            print(f"     æ–‡æœ¬é•¿åº¦: {text_lengths.tolist()}")
            print(f"     ç´¢å¼•å½¢çŠ¶: {text_indices.shape}")
            print(f"     ç´¢å¼•å†…å®¹: {text_indices[:20].tolist()}...")
            
            # æ£€æŸ¥è§£ç 
            start_idx = 0
            for j, length in enumerate(text_lengths):
                indices = text_indices[start_idx:start_idx+length]
                decoded = dataset.decode_prediction(indices.numpy())
                print(f"     è§£ç æµ‹è¯• {j+1}: {texts[j]} -> {decoded}")
                start_idx += length
            
            if i >= 1:  # åªæµ‹è¯•å‰2ä¸ªæ‰¹æ¬¡
                break
                
        return True
        
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_model_output(data_root):
    """æµ‹è¯•æ¨¡å‹è¾“å‡º"""
    print("\nğŸ§  æ¨¡å‹è¾“å‡ºæµ‹è¯•")
    print("=" * 50)
    
    try:
        # åˆ›å»ºæ•°æ®
        train_loader, val_loader, test_loader, dataset = create_data_loaders(
            data_root, batch_size=2, num_workers=0
        )
        
        # æµ‹è¯•åŸºç¡€CRNN
        print("ğŸ“Š æµ‹è¯•åŸºç¡€CRNN:")
        model = BasicCRNN(60, 160, dataset.num_classes)
        model.eval()
        
        with torch.no_grad():
            for images, text_indices, text_lengths, texts in train_loader:
                print(f"   è¾“å…¥å›¾åƒ: {images.shape}")
                
                # å‰å‘ä¼ æ’­
                log_probs = model(images)
                print(f"   æ¨¡å‹è¾“å‡º: {log_probs.shape}")
                print(f"   è¾“å‡ºæ ¼å¼: (seq_len={log_probs.shape[0]}, batch={log_probs.shape[1]}, classes={log_probs.shape[2]})")
                
                # CTCè¾“å…¥é•¿åº¦
                seq_len, batch_size = log_probs.shape[0], log_probs.shape[1]
                input_lengths = torch.full((batch_size,), seq_len, dtype=torch.long)
                print(f"   CTCè¾“å…¥é•¿åº¦: {input_lengths.tolist()}")
                print(f"   ç›®æ ‡é•¿åº¦: {text_lengths.tolist()}")
                
                # è§£ç æµ‹è¯•
                predictions = torch.argmax(log_probs, dim=2)  # (seq_len, batch)
                predictions = predictions.permute(1, 0)  # (batch, seq_len)
                
                for i in range(batch_size):
                    pred_text = dataset.decode_prediction(predictions[i].numpy())
                    true_text = texts[i]
                    print(f"   æ ·æœ¬ {i+1}: çœŸå®='{true_text}' é¢„æµ‹='{pred_text}'")
                
                break
        
        return True
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def visualize_samples(data_root, num_samples=4):
    """å¯è§†åŒ–æ ·æœ¬"""
    print(f"\nğŸ–¼ï¸ æ ·æœ¬å¯è§†åŒ– (å‰{num_samples}ä¸ª)")
    print("=" * 50)
    
    try:
        dataset = CaptchaDataset(os.path.join(data_root, 'train'))
        
        fig, axes = plt.subplots(2, num_samples//2, figsize=(12, 6))
        axes = axes.flatten()
        
        for i in range(min(num_samples, len(dataset))):
            image, _, _, text = dataset[i]
            
            # åå½’ä¸€åŒ–æ˜¾ç¤º
            if isinstance(image, torch.Tensor):
                if image.shape[0] == 3:  # CHWæ ¼å¼
                    image = image.permute(1, 2, 0)
                # å‡è®¾å·²å½’ä¸€åŒ–ï¼Œéœ€è¦åå½’ä¸€åŒ–
                image = image * torch.tensor([0.229, 0.224, 0.225]) + torch.tensor([0.485, 0.456, 0.406])
                image = torch.clamp(image, 0, 1)
            
            axes[i].imshow(image)
            axes[i].set_title(f"'{text}'")
            axes[i].axis('off')
        
        plt.tight_layout()
        plt.savefig('debug_samples.png', dpi=150, bbox_inches='tight')
        print("âœ… æ ·æœ¬å›¾åƒå·²ä¿å­˜åˆ° debug_samples.png")
        
        return True
        
    except Exception as e:
        print(f"âŒ å¯è§†åŒ–å¤±è´¥: {e}")
        return False


def main():
    data_root = "./data"
    
    print("ğŸ”§ CRNNè®­ç»ƒé—®é¢˜è¯Šæ–­å·¥å…·")
    print("=" * 60)
    
    # 1. æ£€æŸ¥æ•°æ®è´¨é‡
    check_data_quality(data_root)
    
    # 2. æµ‹è¯•æ•°æ®åŠ è½½
    if not test_dataloader(data_root):
        print("\nâŒ æ•°æ®åŠ è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®æ ¼å¼")
        return
    
    # 3. æµ‹è¯•æ¨¡å‹
    if not test_model_output(data_root):
        print("\nâŒ æ¨¡å‹æµ‹è¯•å¤±è´¥")
        return
    
    # 4. å¯è§†åŒ–æ ·æœ¬
    try:
        visualize_samples(data_root)
    except:
        print("âš ï¸ æ ·æœ¬å¯è§†åŒ–å¤±è´¥ï¼ˆå¯èƒ½æ²¡æœ‰matplotlibï¼‰")
    
    print("\nğŸ¯ è¯Šæ–­å»ºè®®:")
    print("1. å¦‚æœæ•°æ®æ ¼å¼æ­£ç¡®ï¼Œå°è¯•é™ä½å­¦ä¹ ç‡åˆ°1e-4æˆ–5e-5")
    print("2. æ£€æŸ¥ç”Ÿæˆçš„éªŒè¯ç æ˜¯å¦è¿‡äºå¤æ‚")
    print("3. å°è¯•å‡å°‘éªŒè¯ç é•¿åº¦å˜åŒ–èŒƒå›´")
    print("4. è€ƒè™‘å¢åŠ è®­ç»ƒæ•°æ®é‡")
    print("5. æ£€æŸ¥æ¨¡å‹è¾“å‡ºåºåˆ—é•¿åº¦æ˜¯å¦åˆç†")


if __name__ == "__main__":
    main()